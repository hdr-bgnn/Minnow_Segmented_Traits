import os
import pandas as pd
import xml.etree.ElementTree as ET

configfile: "config/config.yaml"
# names come from the config file

DATAVERSE_CONFIG_PATH = os.path.expanduser('~/.dataverse')
DATAVERSE_CONTAINER = 'docker://ghcr.io/imageomics/dataverse-access:1'



rule all:
    input:
        presence_absence_matrix=config["Presence_Absence_Matrix"],
        sampling_species_burress=config["Sampling_Species_Burress"],
        sampling_minnows_seg=config["Sampling_Minnows_Seg"],
        sampling_df_seg=config["Sampling_DF_Seg"],
        presence_absence_dist_image=config["Presence_Absence_Dist_Image"],
        heatmap_avg_blob_image=config["Heatmap_Avg_Blob_Image"],
        heatmap_sd_blob_image=config["Heatmap_SD_Blob_Image"]


rule download_fish_air_data:
    output: 
        config["Image_Metadata"],
        config["Image_Quality_Metadata"]
    params:
        doi=config["Image_DOI"],
        config=DATAVERSE_CONFIG_PATH
    container:
        DATAVERSE_CONTAINER
    shell: 'DATAVERSE_CONFIG_PATH={params.config} dva download {params.doi} Files/'

rule download_burress:
    output: config["Burress"]
    params:
        doi=config["Burress_DOI"],
        config=DATAVERSE_CONFIG_PATH
    container:
        DATAVERSE_CONTAINER
    shell: 'DATAVERSE_CONFIG_PATH={params.config} dva download {params.doi} Files/'

rule dependencies:
    input: "dependencies.R"
    output: directory("Library")
    shell: 'mkdir Library && R_LIBS_USER=Library Rscript dependencies.R'

checkpoint select_minnow_images:
    input:
        config["Image_Metadata"],
        config["Image_Quality_Metadata"],
        config["Burress"],
        "Library"

    output:
        config["Burress_Minnow_Filtered"],
        config["Sampling"]
    params:
        script=srcdir("../Scripts/Minnow_Selection_Image_Quality_Metadata.R")
    shell:
        "R_LIBS_USER=Library Rscript {params.script}"

# import BGNN_Snakemake rules used to create morpology presence.json files for images
module segmentation:
    snakefile:
        github("hdr-bgnn/BGNN_Core_Workflow", path="workflow/Snakefile", tag="1.0.0")
    # Store all files in a subdirectory
    prefix: "segmentation"

def get_term_map(meta_path, target_file):
    """
    Create a dictionary of term to column number for a filename(target_file)
    in the read Fish-AIR meta.xml file(meta_path).
    """
    tree = ET.parse(meta_path)
    root = tree.getroot()
    for fileinfo in root:
        location = fileinfo.find("files").find("location").text
        if location == target_file:
            term_map = {}
            for fieldinfo in fileinfo:
                index = fieldinfo.attrib.get("index")
                term = fieldinfo.attrib.get("term")
                if term and index:
                    term_map[term] = int(index)
            return term_map
    raise ValueError(f"No term info found for {target_file} in {meta_path}")

def get_image_url(wildcards):
    filename = checkpoints.select_minnow_images.get().output[0]
    df = pd.read_csv(filename)
    term_map = get_term_map(config["File_Metadata"], os.path.basename(filename))
    ark_id_idx = term_map.get(config["Term_ARK"])
    url_column_idx = term_map.get(config["Term_URL"])
    # The segmentation workflow names images 'Images/{image}.jpg' so for us `image` is an arkID
    row = df[df.iloc[:,ark_id_idx] == wildcards.image]
    url = row.iloc[:, url_column_idx].item()
    return url

use rule download_image from segmentation as seg_download_image with:
   params: download_link=get_image_url
use rule generate_metadata from segmentation as seg_generate_metadata
use rule transform_metadata from segmentation as seg_transform_metadata
use rule crop_image from segmentation as seg_crop_image
use rule segment_image from segmentation as seg_segment_image

rule create_morphological_analysis:
    input:
        image = 'segmentation/Segmented/{image}_segmented.png',
        metadata = 'segmentation/Metadata/{image}.json'
    output: 'Morphology/Presence/{image}_presence.json'
    log: 'logs/create_morphological_analysis_{image}.log'
    container:
        "docker://ghcr.io/hdr-bgnn/morphology-analysis/morphology:1.0.0"
    shell:
        'Morphology_main.py {input.image} --metadata {input.metadata} {output} > {log} 2>&1'

def get_image_names(csv_filename):
    df = pd.read_csv(csv_filename)
    # Create 'name' column by removing the filename extension from 'original_file_name'
    names = df['original_file_name'].apply(lambda x : os.path.splitext(x)[0])
    return names.tolist()

def presence_absence_analysis_inputs(wildcards):
    # Returns output morphology presence filenames based on Burress_Minnow_Filtered
    with checkpoints.select_minnow_images.get(**wildcards).output[0].open() as f:
       names = get_image_names(f)
    presence_files = [f"Morphology/Presence/{i}_presence.json" for i in names]
    return {
        "presence_files": presence_files,
        "sampling": config["Sampling"],
        "image_metadata": config["Image_Metadata"],
        "image_quality_metadata": config["Image_Quality_Metadata"],
        "burress": config["Burress"],
        "library": "Library"
    }

rule presence_absence_analysis:
    input:
       unpack(presence_absence_analysis_inputs)
    output:
       presence_absence_matrix=config["Presence_Absence_Matrix"],
       sampling_species_burress=config["Sampling_Species_Burress"],
       sampling_minnows_seg=config["Sampling_Minnows_Seg"],
       sampling_df_seg=config["Sampling_DF_Seg"],
       presence_absence_dist_image=config["Presence_Absence_Dist_Image"],
       heatmap_avg_blob_image=config["Heatmap_Avg_Blob_Image"],
       heatmap_sd_blob_image=config["Heatmap_SD_Blob_Image"]
    params:
        script=srcdir("../Scripts/Presence_Absence_Analysis.R"),
    shell:
        "R_LIBS_USER=Library Rscript {params.script}"
