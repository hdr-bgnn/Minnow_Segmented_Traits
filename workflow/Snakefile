import os
import pandas as pd

configfile: "config/config.yaml"
    # names come from the config file

DATAVERSE_CONFIG_PATH = os.path.expanduser('~/.dataverse')
DATAVERSE_CONTAINER = 'docker://ghcr.io/imageomics/dataverse-access:0.0.3'

def get_image_names(csv_filename):
    df = pd.read_csv(csv_filename)
    # Create 'name' column by removing the filename extension from 'original_file_name'
    names = df['original_file_name'].apply(lambda x : os.path.splitext(x)[0])
    return names.tolist()

def selection_criteria_inputs(wildcards):
    # Returns output morphology presence filenames
    with checkpoints.select_minnow_images.get(**wildcards).output[1].open() as f:
       names = get_image_names(f)
    presence_files = [f"segmentation/Morphology/Presence/{i}_presence.json" for i in names]
    return {
        "presence_files": presence_files,
        "sampling": config["Sampling"],
        "image_metadata": config["Image_Metadata"],
        "image_quality_metadata": config["Image_Quality_Metadata"],
        "burress": config["Burress"]
    }

rule all:
    input:
        presence_absence_matrix=config["Presence_Absence_Matrix"],
        sampling_species_burress=config["Sampling_Species_Burress"],
        sampling_minnows_seg=config["Sampling_Minnows_Seg"],
        sampling_df_seg=config["Sampling_DF_Seg"],
        presence_absence_dist_image=config["Presence_Absence_Dist_Image"],
        heatmap_avg_blob_image=config["Heatmap_Avg_Blob_Image"],
        heatmap_sd_blob_image=config["Heatmap_SD_Blob_Image"]
 
rule download_image_metadata:
    output: config["Image_Metadata"]
    params:
        doi=config["Image_Metadata_DOI"],
        config=DATAVERSE_CONFIG_PATH
    container:
        DATAVERSE_CONTAINER
    shell: 'DATAVERSE_CONFIG_PATH={params.config} dva download {params.doi} Files/'

rule download_image_quality_metadata:
    output: config["Image_Quality_Metadata"]
    params:
        doi=config["Image_Quality_Metadata_DOI"],
        config=DATAVERSE_CONFIG_PATH
    container:
        DATAVERSE_CONTAINER
    shell: 'DATAVERSE_CONFIG_PATH={params.config} dva download {params.doi} Files/'

rule download_burress:
    output: config["Burress"]
    params:
        doi=config["Burress_DOI"],
        config=DATAVERSE_CONFIG_PATH
    container:
        DATAVERSE_CONTAINER
    shell: 'DATAVERSE_CONFIG_PATH={params.config} dva download {params.doi} Files/'

checkpoint select_minnow_images:
    input:
        config["Image_Metadata"],
        config["Image_Quality_Metadata"],
        config["Burress"]
    output:
        config["Minnow_Filtered"],
        config["Burress_Minnow_Filtered"],
        config["Sampling"]
    params:
        script=srcdir("../Scripts/Minnow_Selection_Image_Quality_Metadata.R")
    shell:
        "R_LIBS_USER=Library Rscript {params.script}"

# import BGNN_Snakemake rules used to create morpology presence.json files for images
module segmentation:
    snakefile:
        github("hdr-bgnn/BGNN_Snakemake", path="workflow/Snakefile", tag="84e3604a6f767c43b31259237ab1ffc61bac3be8")
    # Use output from Minnow_Selection_Image_Quality_Metadata.R as input files
    config: { "list": config["Burress_Minnow_Filtered"] }
    # Store all files in a subdirectory
    prefix: "segmentation"
use rule * from segmentation as seg_*

rule selection_criteria_segmented_images:
    input:
       unpack(selection_criteria_inputs)
    output:
       presence_absence_matrix=config["Presence_Absence_Matrix"],
       sampling_species_burress=config["Sampling_Species_Burress"],
       sampling_minnows_seg=config["Sampling_Minnows_Seg"],
       sampling_df_seg=config["Sampling_DF_Seg"],
       presence_absence_dist_image=config["Presence_Absence_Dist_Image"],
       heatmap_avg_blob_image=config["Heatmap_Avg_Blob_Image"],
       heatmap_sd_blob_image=config["Heatmap_SD_Blob_Image"]
    params:
        script=srcdir("../Scripts/Selection_Criteria_Segmented_Images.R"),
    shell:
        "R_LIBS_USER=Library Rscript {params.script}"

